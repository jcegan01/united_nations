---
title: "R Notebook"
output: html_notebook
---

```{r}
tm_pkgs = c('tm','SnowballC','RColorBrewer','wordcloud')
inst = lapply(tm_pkgs, library, character.only = TRUE) # load them
```

#### Read text and create term document matrix

```{r}
#read in word file without password protection
file <- "UNFCCC. List of Participants, COP22-part1.txt"
text <- readLines(paste0('input/',file))

# # Load the data as a corpus
# docs <- Corpus(VectorSource(text))
# 
# toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
# docs <- tm_map(docs, toSpace, "/")
# docs <- tm_map(docs, toSpace, "@")
# docs <- tm_map(docs, toSpace, "\\|")
# 
# # Convert the text to lower case
# docs <- tm_map(docs, content_transformer(tolower))
# # Remove numbers
# docs <- tm_map(docs, removeNumbers)
# # Remove english common stopwords
# docs <- tm_map(docs, removeWords, stopwords("english"))
# # Remove your own stop word
# # specify your stopwords as a character vector
# docs <- tm_map(docs, removeWords, c("blabla1", "blabla2")) 
# # Remove punctuations
# docs <- tm_map(docs, removePunctuation)
# # Eliminate extra white spaces
# docs <- tm_map(docs, stripWhitespace)
# # Text stemming
# docs <- tm_map(docs, stemDocument)
# 
# #Create term document matrix
# dtm <- TermDocumentMatrix(docs)
# m <- as.matrix(dtm)
# v <- sort(rowSums(m),decreasing=TRUE)
# d <- data.frame(word = names(v),freq=v)
# head(d, 10)
```
